import numpy as np
import networkx as nx
from typing import Dict, List, Any, Optional, Tuple
from enum import Enum, auto
import math

class QuantumState(Enum):
    SUPERPOSITION = auto()
    ENTANGLED = auto()
    COLLAPSED = auto()

class EmergentNode:
    """Node in the quantum-inspired emergent intelligence network"""
    
    def __init__(self, id: str, dimensions: int = 4):
        self.id = id
        self.state_vector = np.random.random(dimensions) * 2 - 1
        self.normalize_state()
        self.connections = []
        self.quantum_state = QuantumState.SUPERPOSITION
        self.evolution_history = []
        self.tension_field = 0.0
        self.adaptation_score = 0.5
        
    def normalize_state(self):
        """Normalize state vector to unit length (quantum state normalization)"""
        norm = np.linalg.norm(self.state_vector)
        if norm > 0:
            self.state_vector = self.state_vector / norm
    
    def entangle_with(self, other_node, strength: float = 1.0):
        """Create quantum entanglement with another node"""
        if self.quantum_state != QuantumState.ENTANGLED:
            # Create entanglement through state vector correlation
            correlation = np.dot(self.state_vector, other_node.state_vector)
            entanglement_vector = self.state_vector + (correlation * strength * other_node.state_vector)
            self.state_vector = entanglement_vector
            self.normalize_state()
            self.quantum_state = QuantumState.ENTANGLED
            self.connections.append((other_node.id, strength, correlation))
    
    def collapse_state(self, observation_vector: Optional[np.ndarray] = None):
        """Collapse quantum state (measurement)"""
        if observation_vector is not None:
            # Project state onto observation vector
            projection = np.dot(self.state_vector, observation_vector)
            self.state_vector = observation_vector * projection
        else:
            # Random collapse
            self.state_vector = (np.random.random(len(self.state_vector)) * 2 - 1)
        
        self.normalize_state()
        self.quantum_state = QuantumState.COLLAPSED
        
    def evolve(self, tension_field: float, nearby_nodes: List['EmergentNode']):
        """Evolve node state based on tension field and nearby nodes"""
        # Record current state
        self.evolution_history.append(self.state_vector.copy())
        
        # Calculate adaptation based on tension field
        adaptation = 1.0 / (1.0 + tension_field)
        
        # Apply quantum tunneling effect - chance to jump to a new state
        if np.random.random() < 0.1 * tension_field:
            jump_vector = np.random.random(len(self.state_vector)) * 2 - 1
            self.state_vector = 0.7 * self.state_vector + 0.3 * jump_vector
            self.normalize_state()
            self.quantum_state = QuantumState.SUPERPOSITION
        
        # Learn from nearby nodes (neural-quantum hybrid learning)
        if nearby_nodes:
            influence = np.zeros_like(self.state_vector)
            for node in nearby_nodes:
                # Weight influence by connection strength
                for conn_id, strength, _ in self.connections:
                    if conn_id == node.id:
                        influence += node.state_vector * strength * adaptation
                        break
            
            # Apply influence
            if np.linalg.norm(influence) > 0:
                self.state_vector = 0.8 * self.state_vector + 0.2 * influence
                self.normalize_state()
        
        # Update adaptation score
        self.adaptation_score = 0.9 * self.adaptation_score + 0.1 * adaptation

class EmergentIntelligenceNetwork:
    """Quantum-inspired network with emergent intelligence properties"""
    
    def __init__(self, dimensions: int = 4, resolution: int = 64):
        self.dimensions = dimensions
        self.resolution = resolution
        self.nodes = {}  # id -> EmergentNode
        self.graph = nx.DiGraph()
        self.tension_field = np.zeros([resolution] * dimensions)
        self.emergent_patterns = []
        self.evolution_steps = 0
        self.global_coherence = 0.0
        
        # Computational spaces
        self.hilbert_space = np.zeros([resolution] * 2, dtype=complex)
        self.phase_space = np.zeros([resolution] * 2)
        
    def add_node(self, id: Optional[str] = None) -> str:
        """Add a new node to the network"""
        if id is None:
            id = f"node_{len(self.nodes)}"
            
        node = EmergentNode(id, self.dimensions)
        self.nodes[id] = node
        self.graph.add_node(id, state=node.state_vector, quantum_state=node.quantum_state)
        
        return id
    
    def connect_nodes(self, node1_id: str, node2_id: str, strength: float = 1.0) -> bool:
        """Connect two nodes with quantum entanglement"""
        if node1_id not in self.nodes or node2_id not in self.nodes:
            return False
            
        node1 = self.nodes[node1_id]
        node2 = self.nodes[node2_id]
        
        # Create bidirectional entanglement
        node1.entangle_with(node2, strength)
        node2.entangle_with(node1, strength)
        
        # Update graph
        correlation = np.dot(node1.state_vector, node2.state_vector)
        self.graph.add_edge(node1_id, node2_id, weight=strength, correlation=correlation)
        self.graph.add_edge(node2_id, node1_id, weight=strength, correlation=correlation)
        
        return True
    
    def update_tension_field(self):
        """Update the quantum tension field across the network"""
        # Reset tension field
        self.tension_field = np.zeros([self.resolution] * self.dimensions)
        
        # Calculate tensions between nodes
        for node_id, node in self.nodes.items():
            # Convert node state to grid coordinates
            grid_pos = self._continuous_to_grid(node.state_vector)
            
            # Increase tension based on connections
            for conn_id, strength, correlation in node.connections:
                if conn_id in self.nodes:
                    other_node = self.nodes[conn_id]
                    other_grid_pos = self._continuous_to_grid(other_node.state_vector)
                    
                    # Calculate tension line between nodes
                    self._add_tension_between_points(grid_pos, other_grid_pos, strength, correlation)
        
        # Normalize tension field
        max_tension = np.max(self.tension_field)
        if max_tension > 0:
            self.tension_field = self.tension_field / max_tension
    
    def _continuous_to_grid(self, position: np.ndarray) -> Tuple:
        """Convert continuous position to grid coordinates"""
        # Map from [-1, 1] to [0, resolution-1]
        grid_coords = tuple((position + 1) / 2 * (self.resolution - 1))
        # Ensure coordinates are within bounds
        return tuple(min(self.resolution - 1, max(0, int(c))) for c in grid_coords)
    
    def _add_tension_between_points(self, point1: Tuple, point2: Tuple, strength: float, correlation: float):
        """Add tension between two points in the field"""
        # For simplicity, we'll just add tension at the endpoints
        # In a real implementation, we would use a line drawing algorithm
        
        self.tension_field[point1] += strength * (1 - abs(correlation))
        self.tension_field[point2] += strength * (1 - abs(correlation))
    
    def evolve_network(self, steps: int = 1):
        """Evolve the network through quantum-classical hybrid dynamics"""
        for _ in range(steps):
            # Update tension field
            self.update_tension_field()
            
            # Get network properties
            centrality = nx.eigenvector_centrality_numpy(self.graph, weight='weight')
            communities = list(nx.algorithms.community.greedy_modularity_communities(self.graph.to_undirected()))
            
            # Evolve each node
            for node_id, node in self.nodes.items():
                # Get node's grid position
                grid_pos = self._continuous_to_grid(node.state_vector)
                
                # Get local tension
                local_tension = self.tension_field[grid_pos]
                
                # Find nearby nodes (in network space, not physical space)
                nearby_nodes = []
                for neighbor_id in self.graph.neighbors(node_id):
                    nearby_nodes.append(self.nodes[neighbor_id])
                
                # Evolve node
                node.evolve(local_tension, nearby_nodes)
                
                # Update graph with new state
                self.graph.nodes[node_id]['state'] = node.state_vector
                self.graph.nodes[node_id]['quantum_state'] = node.quantum_state
            
            # Calculate global coherence
            self.global_coherence = self._calculate_coherence()
            
            # Detect emergent patterns
            if self.evolution_steps % 10 == 0:
                self._detect_emergent_patterns()
            
            # Update Hilbert and phase spaces
            self._update_computational_spaces()
            
            self.evolution_steps += 1
    
    def _calculate_coherence(self) -> float:
        """Calculate network global coherence"""
        if len(self.nodes) < 2:
            return 0.0
            
        total_correlation = 0.0
        pairs = 0
        
        for node1_id, node1 in self.nodes.items():
            for node2_id, node2 in self.nodes.items():
                if node1_id != node2_id:
                    correlation = abs(np.dot(node1.state_vector, node2.state_vector))
                    total_correlation += correlation
                    pairs += 1
        
        return total_correlation / max(1, pairs)
    
    def _detect_emergent_patterns(self):
        """Detect emergent patterns in the network"""
        # Only look for patterns if we have enough nodes
        if len(self.nodes) < 5:
            return
            
        # Get all node positions
        positions = np.array([node.state_vector for node in self.nodes.values()])
        
        # Clustering to find spatial patterns
        from sklearn.cluster import KMeans
        
        # Determine optimal number of clusters using silhouette score
        max_clusters = min(10, len(positions) // 2)
        best_score = -1
        best_n_clusters = 2
        
        for n_clusters in range(2, max_clusters + 1):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            cluster_labels = kmeans.fit_predict(positions)
            
            if len(set(cluster_labels)) > 1:  # Ensure multiple clusters
                from sklearn.metrics import silhouette_score
                score = silhouette_score(positions, cluster_labels)
                if score > best_score:
                    best_score = score
                    best_n_clusters = n_clusters
        
        # Use best number of clusters
        kmeans = KMeans(n_clusters=best_n_clusters, random_state=42)
        cluster_labels = kmeans.fit_predict(positions)
        
        # Check if clusters are significant
        if best_score > 0.6:  # Good cluster separation
            pattern = {
                'type': 'spatial_clustering',
                'score': best_score,
                'n_clusters': best_n_clusters,
                'centers': kmeans.cluster_centers_.tolist(),
                'step': self.evolution_steps,
                'coherence': self.global_coherence
            }
            
            # Check if this is a new pattern
            is_new = True
            for existing in self.emergent_patterns:
                if existing['type'] == 'spatial_clustering':
                    similarity = self._compare_patterns(existing, pattern)
                    if similarity > 0.8:  # Similar pattern already exists
                        is_new = False
                        break
            
            if is_new:
                self.emergent_patterns.append(pattern)
    
    def _compare_patterns(self, pattern1: Dict, pattern2: Dict) -> float:
        """Compare two patterns for similarity"""
        if pattern1['type'] != pattern2['type']:
            return 0.0
            
        if pattern1['type'] == 'spatial_clustering':
            centers1 = np.array(pattern1['centers'])
            centers2 = np.array(pattern2['centers'])
            
            # Calculate distances between all pairs of centers
            min_dists = []
            for c1 in centers1:
                dists = np.linalg.norm(centers2 - c1.reshape(1, -1), axis=1)
                min_dists.append(np.min(dists))
            
            # Calculate average distance
            avg_dist = np.mean(min_dists)
            
            # Convert distance to similarity score
            similarity = math.exp(-avg_dist * 5)  # Scale factor of 5 for steeper falloff
            
            return similarity
        
        return 0.0
    
    def _update_computational_spaces(self):
        """Update computational spaces for analysis"""
        # Select two dimensions for visualization
        dim1, dim2 = 0, 1
        
        # Update phase space (position-momentum projection)
        for node in self.nodes.values():
            # Get position in first two dimensions
            pos = node.state_vector[dim1:dim2+1]
            
            # Estimate momentum from evolution history
            if len(node.evolution_history) >= 2:
                prev = node.evolution_history[-1][dim1:dim2+1]
                momentum = pos - prev
            else:
                momentum = np.zeros(2)
            
            # Convert to grid coordinates
            x = int((pos[0] + 1) / 2 * (self.resolution - 1))
            y = int((momentum[0] + 1) / 2 * (self.resolution - 1))
            
            x = min(self.resolution - 1, max(0, x))
            y = min(self.resolution - 1, max(0, y))
            
            # Update phase space
            self.phase_space[x, y] += 1
        
        # Update Hilbert space (quantum probability amplitude)
        self.hilbert_space = np.zeros([self.resolution] * 2, dtype=complex)
        for node in self.nodes.values():
            # Project quantum state onto 2D
            amplitude = node.state_vector[dim1] + 1j * node.state_vector[dim2]
            
            # Convert to grid coordinates
            x = int((np.real(amplitude) + 1) / 2 * (self.resolution - 1))
            y = int((np.imag(amplitude) + 1) / 2 * (self.resolution - 1))
            
            x = min(self.resolution - 1, max(0, x))
            y = min(self.resolution - 1, max(0, y))
            
            # Update Hilbert space
            self.hilbert_space[x, y] += amplitude
    
    def analyze_structure(self) -> Dict[str, Any]:
        """Analyze the network structure and return metrics"""
        result = {
            'nodes': len(self.nodes),
            'edges': self.graph.number_of_edges(),
            'coherence': self.global_coherence,
            'emergent_patterns': len(self.emergent_patterns),
            'evolution_steps': self.evolution_steps
        }
        
        # Calculate graph metrics if enough nodes
        if len(self.nodes) > 1:
            try:
                # Get connectedness
                connected = nx.is_connected(self.graph.to_undirected())
                result['connected'] = connected
                
                # Get clustering coefficient
                clustering = nx.average_clustering(self.graph.to_undirected())
                result['clustering'] = clustering
                
                # Get modularity
                communities = list(nx.algorithms.community.greedy_modularity_communities(self.graph.to_undirected()))
                result['communities'] = len(communities)
                
                # Get centrality measures
                degree_centrality = nx.degree_centrality(self.graph)
                result['max_degree_centrality'] = max(degree_centrality.values())
                
                betweenness_centrality = nx.betweenness_centrality(self.graph)
                result['max_betweenness_centrality'] = max(betweenness_centrality.values())
                
                # Get average path length if connected
                if connected:
                    avg_path_length = nx.average_shortest_path_length(self.graph)
                    result['avg_path_length'] = avg_path_length
                    
                    # Calculate small-world coefficient
                    random_graph = nx.gnm_random_graph(len(self.nodes), self.graph.number_of_edges())
                    random_clustering = nx.average_clustering(random_graph)
                    
                    if random_clustering > 0:
                        sigma = (clustering / random_clustering)
                        result['small_world_coefficient'] = sigma
            except:
                # Handle any graph algorithm errors
                pass
        
        return result

# Integration with file analysis
class QuantumAwareCodeAnalyzer:
    """Quantum-aware code analyzer that builds an emergent intelligence model from code"""
    
    def __init__(self, dimensions: int = 4):
        self.network = EmergentIntelligenceNetwork(dimensions=dimensions)
        self.file_to_node_map = {}  # file_path -> node_id
        self.symbol_to_node_map = {}  # symbol name -> node_id
        self.dependency_strength = {}  # (node1, node2) -> strength
    
    def analyze_file(self, file_path: str) -> str:
        """Analyze a file and add it to the network"""
        # Create a node for the file
        node_id = self.network.add_node()
        self.file_to_node_map[file_path] = node_id
        
        # Extract key information from file
        import os
        file_name = os.path.basename(file_path)
        ext = os.path.splitext(file_name)[1].lower()
        
        # Read file content
        with open(file_path, 'r', errors='ignore') as f:
            content = f.read()
        
        # Extract symbols based on file type
        symbols = self._extract_symbols(content, ext)
        
        # Create nodes for symbols
        for symbol in symbols:
            symbol_node_id = self.network.add_node()
            self.symbol_to_node_map[symbol] = symbol_node_id
            
            # Connect file node to symbol node
            self.network.connect_nodes(node_id, symbol_node_id, 0.8)
        
        # Update network evolution
        self.network.evolve_network(5)
        
        return node_id
    
    def _extract_symbols(self, content: str, ext: str) -> List[str]:
        """Extract symbols from file content based on extension"""
        symbols = []
        
        if ext == '.py':
            # Extract Python functions, classes
            import re
            function_pattern = re.compile(r'def\s+(\w+)\s*\(')
            class_pattern = re.compile(r'class\s+(\w+)')
            
            functions = function_pattern.findall(content)
            classes = class_pattern.findall(content)
            
            symbols.extend(functions)
            symbols.extend(classes)
            
        elif ext in ['.js', '.ts']:
            # Extract JavaScript/TypeScript functions, classes
            import re
            function_pattern = re.compile(r'function\s+(\w+)|const\s+(\w+)\s*=\s*\(')
            class_pattern = re.compile(r'class\s+(\w+)')
            
            functions = function_pattern.findall(content)
            classes = class_pattern.findall(content)
            
            symbols.extend([f[0] or f[1] for f in functions if f[0] or f[1]])
            symbols.extend(classes)
            
        elif ext in ['.c', '.cpp', '.h', '.hpp']:
            # Extract C/C++ functions, classes
            import re
            function_pattern = re.compile(r'(\w+)\s*\([^)]*\)\s*\{')
            class_pattern = re.compile(r'class\s+(\w+)|struct\s+(\w+)')
            
            functions = function_pattern.findall(content)
            classes = class_pattern.findall(content)
            
            symbols.extend(functions)
            symbols.extend([c[0] or c[1] for c in classes if c[0] or c[1]])
        
        return symbols
    
    def analyze_dependencies(self, file_paths: List[str]):
        """Analyze dependencies between files"""
        # Ensure all files are in the network
        for file_path in file_paths:
            if file_path not in self.file_to_node_map:
                self.analyze_file(file_path)
        
        # Build dependency graph
        import re
        
        for file_path in file_paths:
            with open(file_path, 'r', errors='ignore') as f:
                content = f.read()
            
            file_node = self.file_to_node_map[file_path]
            ext = os.path.splitext(file_path)[1].lower()
            
            # Find import statements based on file type
            if ext == '.py':
                import_pattern = re.compile(r'import\s+(\w+)|from\s+(\w+)\s+import')
                imports = import_pattern.findall(content)
                
                for imp in imports:
                    module = imp[0] or imp[1]
                    # Look for matching file
                    for other_path in file_paths:
                        if module in other_path:
                            other_node = self.file_to_node_map[other_path]
                            self.network.connect_nodes(file_node, other_node, 0.7)
                            self.dependency_strength[(file_node, other_node)] = 0.7
            
            elif ext in ['.js', '.ts']:
                import_pattern = re.compile(r'import\s+.*from\s+[\'"](.+)[\'"]|require\s*\(\s*[\'"](.+)[\'"]\s*\)')
                imports = import_pattern.findall(content)
                
                for imp in imports:
                    module = imp[0] or imp[1]
                    # Look for matching file
                    for other_path in file_paths:
                        if module in other_path:
                            other_node = self.file_to_node_map[other_path]
                            self.network.connect_nodes(file_node, other_node, 0.7)
                            self.dependency_strength[(file_node, other_node)] = 0.7
            
            elif ext in ['.c', '.cpp', '.h', '.hpp']:
                import_pattern = re.compile(r'#include\s+[<"](.+)[>"]')
                imports = import_pattern.findall(content)
                
                for imp in imports:
                    # Look for matching file
                    for other_path in file_paths:
                        if imp in other_path:
                            other_node = self.file_to_node_map[other_path]
                            self.network.connect_nodes(file_node, other_node, 0.7)
                            self.dependency_strength[(file_node, other_node)] = 0.7
        
        # Evolve network with new connections
        self.network.evolve_network(10)
    
    def get_analysis_report(self) -> Dict[str, Any]:
        """Get comprehensive analysis report"""
        # Get general network metrics
        metrics = self.network.analyze_structure()
        
        # Get file metrics
        file_metrics = {}
        for file_path, node_id in self.file_to_node_map.items():
            centrality = nx.eigenvector_centrality_numpy(self.network.graph)[node_id]
            
            dependencies = []
            for neighbor in self.network.graph.neighbors(node_id):
                if neighbor in self.file_to_node_map.values():
                    strength = self.network.graph[node_id][neighbor].get('weight', 0.0)
                    dependencies.append({
                        'node_id': neighbor,
                        'strength': strength
                    })
            
            file_metrics[file_path] = {
                'node_id': node_id,
                'centrality': centrality,
                'dependencies': dependencies
            }
        
        # Get emergent patterns
        patterns = self.network.emergent_patterns
        
        return {
            'metrics': metrics,
            'file_metrics': file_metrics,
            'patterns': patterns,
            'coherence': self.network.global_coherence
        }

